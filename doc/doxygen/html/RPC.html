<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.9"/>
<title>GraphLab: Distributed Graph-Parallel API: GraphLab RPC</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">GraphLab: Distributed Graph-Parallel API
   &#160;<span id="projectnumber">2.2</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.9 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('RPC.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">GraphLab RPC </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>GraphLab RPC primary design goal was to provide a convenient and easy to use asynchronous communication system between <b>identical</b> binaries running on different machines over a distributed network. It therefore provides MPI-like capabilities together with RPC functionality. The GraphLab distributed implementation is built on top of this RPC library.</p>
<p>GraphLab RPC uses extensive template meta-programming techniques to provide an <b>IDL-free</b> (<a href="http://en.wikipedia.org/wiki/Interface_description_language">http://en.wikipedia.org/wiki/Interface_description_language</a>) RPC system, allowing arbitrary functions to be called on program running on remote machines (Note that all machines must be running the same binary).</p>
<p>For instance, this is a particularly interesting example: </p><div class="fragment"><div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;graphlab/rpc/dc.hpp&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;graphlab/rpc/dc_init_from_mpi.hpp&gt;</span></div>
<div class="line"><span class="keyword">using namespace </span><a class="code" href="namespacegraphlab.html">graphlab</a>;</div>
<div class="line"></div>
<div class="line"><span class="keywordtype">int</span> main(<span class="keywordtype">int</span> argc, <span class="keywordtype">char</span> ** argv) {</div>
<div class="line">  mpi_tools::init(argc, argv);</div>
<div class="line"></div>
<div class="line">  <a class="code" href="classgraphlab_1_1distributed__control.html">distributed_control</a> dc;</div>
<div class="line">  </div>
<div class="line">  <span class="keywordflow">if</span> (dc.<a class="code" href="classgraphlab_1_1distributed__control.html#a3adaa364edf63ff764aa2aabbe777f65">procid</a>() == 0 &amp;&amp; dc.<a class="code" href="classgraphlab_1_1distributed__control.html#a688dac1ed2de771d65f93d7aae739fd1">numprocs</a>() &gt;= 2) {</div>
<div class="line">    dc.<a class="code" href="classgraphlab_1_1distributed__control.html#aa0387b77bb3b5505d55fbebedd499b77">remote_call</a>(1, printf, <span class="stringliteral">&quot;%d + %f = %s\n&quot;</span>, 1, 2.0, <span class="stringliteral">&quot;three&quot;</span>);</div>
<div class="line">  }</div>
<div class="line">  dc.<a class="code" href="classgraphlab_1_1distributed__control.html#a32f0ebebb86a593fa56bf2c567f8c466">barrier</a>();</div>
<div class="line">}</div>
</div><!-- fragment --><p>The distributed_control constructor will first detect if MPI is initialized, and if it is, will use MPI to perform initialization (<a class="el" href="RPC.html#sec_spawning_mpi">Spawning with MPI</a>). If MPI is not initialized, then the constructor will check if an alternate spawning process using environment variables is used (<a class="el" href="RPC.html#sec_spawning_rpcexec">Spawning with rpcexec.py</a>). The environment variable based spawning process is less reliable, but useful in situations where MPI is not available.</p>
<p>Once the distributed_control object is created, <a class="el" href="classgraphlab_1_1distributed__control.html#a3adaa364edf63ff764aa2aabbe777f65">dc.procid()</a> provides the current machine number, while <a class="el" href="classgraphlab_1_1distributed__control.html#a688dac1ed2de771d65f93d7aae739fd1">dc.numprocs()</a> provide the total number of machines.</p>
<p>The if-condition is therefore entered by only the first machine, which performs a remote call to the second machine (the first argument of remote_call is the target machine ID). The second machine will then execute the equivalent of </p><div class="fragment"><div class="line">printf(<span class="stringliteral">&quot;%d + %f = %s\n&quot;</span>, 1, 2.0, <span class="stringliteral">&quot;three&quot;</span>);</div>
</div><!-- fragment --><p>We will discuss the different aspects of the RPC library seperately: </p><ul>
<li>Spawning <br />
 Initialization and Starting a distributed program using GraphLab RPC </li>
<li>Basic_RPC <br />
 Basic usage of the RPC library. Calling of simple functions. </li>
<li><a class="el" href="RPC.html#OOP_RPC">Distributed Objects</a> <br />
 Advanced usage of the RPC library. Creating and managing distributed object contexts. </li>
<li><a class="el" href="RPC.html#Fiber_RPC">Fiber Compatible Remote Requests</a> <br />
 Fiber-compatible remote request calls.</li>
</ul>
<h1><a class="anchor" id="sec_examples"></a>
Examples</h1>
<p>The tests/ directory include a collection of nine RPC examples demonstrating all the key features.</p>
<ul>
<li>RPC Example 1: Basic Synchronous RPC <a class="el" href="rpc__example1_8cpp_source.html">rpc_example1.cpp</a> </li>
<li>RPC Example 2: Asynchronous RPC with Built-in Serialization <a class="el" href="rpc__example2_8cpp_source.html">rpc_example2.cpp</a> </li>
<li>RPC Example 3: Asynchronous RPC with Struct POD Serialization <a class="el" href="rpc__example3_8cpp_source.html">rpc_example3.cpp</a> </li>
<li>RPC Example 4: Asynchronous RPC with Manual Serialization <a class="el" href="rpc__example4_8cpp_source.html">rpc_example4.cpp</a> </li>
<li>RPC Example 5: Asynchronous RPC to printf <a class="el" href="rpc__example5_8cpp_source.html">rpc_example5.cpp</a> </li>
<li>RPC Example 6: Asynchronous RPC with <a class="el" href="classgraphlab_1_1any.html">graphlab::any</a> <a class="el" href="rpc__example6_8cpp_source.html">rpc_example6.cpp</a> </li>
<li>RPC Example 7: Distributed Object <a class="el" href="rpc__example7_8cpp_source.html">rpc_example7.cpp</a> </li>
<li>RPC Example 8: RPC using iterators over machines <a class="el" href="rpc__example8_8cpp_source.html">rpc_example8.cpp</a> </li>
<li>RPC Example 9: Distributed Object RPC using iterators over machines <a class="el" href="rpc__example9_8cpp_source.html">rpc_example9.cpp</a></li>
</ul>
<h1><a class="anchor" id="sec_spawning"></a>
Spawning and Initialization</h1>
<p>Spawning is the process of starting an instance of GraphLab RPC on seperate machines. GraphLab RPC supports two spawning methods: MPI or rpcexec.py (a script in the scripts/ directory). The MPI method is <b>strongly recommended</b> and is the most reliable.</p>
<h2><a class="anchor" id="sec_spawning_mpi"></a>
Spawning with MPI</h2>
<p>GraphLab was tested with MPICH2, but should also with OpenMPI. Refer to the documentation for MPICH2 or OpenMPI to set up MPI and make sure that you can run the basic test MPI programs (MPICH2 comes with an mpdringtest).</p>
<p>No additional configuration is necessary to spawn a GraphLab RPC program with MPI.</p>
<p>The GraphLab RPC program should begin with:</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;graphlab/rpc/dc.hpp&gt;</span></div>
<div class="line"><span class="keyword">using namespace </span><a class="code" href="namespacegraphlab.html">graphlab</a>;</div>
<div class="line"></div>
<div class="line"><span class="keywordtype">int</span> main(<span class="keywordtype">int</span> argc, <span class="keywordtype">char</span> ** argv) {</div>
<div class="line">  mpi_tools::init(argc, argv);</div>
<div class="line">  <a class="code" href="classgraphlab_1_1distributed__control.html">distributed_control</a> dc;</div>
<div class="line">  ...</div>
<div class="line">}</div>
</div><!-- fragment --><p>In this case, distributed_control detects that MPI was initialized prior and will use MPI to perform initial negotiation of port numbers.</p>
<h2><a class="anchor" id="sec_spawning_rpcexec"></a>
Spawning with rpcexec.py</h2>
<p>rpcexec.py provides an alternative, less reliable way to run a process on a collection of machines, using ssh to communicate between them. <code>rpcexec.py &ndash;help</code> provides some basic help.</p>
<p>You will first need to create a host file which is simply a list of host names and IP addresses: </p><pre class="fragment">localhost
192.168.1.5
node2
node3
localhost
192.168.1.5
node2
node3
</pre><p>Running <code>rpcexec.py -n [num to start] -f [hostsfile] <code>command</code></code> will read the first execute the command on the first N hosts in the hostfile. For instance in this case, running </p><pre class="fragment">rpcexec.py -n 5 -f hostsfile ls
</pre><p> will run the <code>ls</code> bash command twice on the localhost, and once on the three nodes : 192.168.1.5, node2, node3.</p>
<p>rpcexec.py also supports a 'screen' (GNU Screen) mode. Running </p><pre class="fragment">rpcexec.py -s lsscreen -n 3 -f hostsfile ls
</pre><p> will create a <code>screen</code> session with 3 windows where one window ran <code>ls</code> on the localhost, while two other windows sshed into 192.168.1.5 and <code>node2</code>, running the <code>ls</code> on each of them. The screen session will be named "lsscreen"</p>
<p>rpcexec.py will terminate immediately after creating the screen session. </p><pre class="fragment">screen -r lsscreen
</pre><p> will display and resume the screen session.</p>
<p>If rpcexec.py is used to spawn the program, The GraphLab RPC program should begin with: </p><div class="fragment"><div class="line"><span class="preprocessor">#include &lt;graphlab/rpc/dc.hpp&gt;</span></div>
<div class="line"><span class="keyword">using namespace </span><a class="code" href="namespacegraphlab.html">graphlab</a>;</div>
<div class="line"></div>
<div class="line"><span class="keywordtype">int</span> main(<span class="keywordtype">int</span> argc, <span class="keywordtype">char</span> ** argv) {</div>
<div class="line">  <a class="code" href="classgraphlab_1_1distributed__control.html">distributed_control</a> dc;</div>
<div class="line">  ...</div>
<div class="line">}</div>
</div><!-- fragment --><p>Since unlike MPI spawning, there is no existing channel for communicating port information between the machines. rpcexec.py therefore uses environment variables to pass information to the GraphLab RPC process. The following two environment variables are used: </p><ul>
<li><b>SPAWNNODES</b> A comma seperated list of hostnames participating in the distributed program </li>
<li><b>SPAWNID:</b> The index of the current machine into the SPAWNNODES list. First machine has an index value of 0.</li>
</ul>
<p>A machine will listen on the port 10000 + SPAWNID.</p>
<p>See <a class="el" href="structgraphlab_1_1dc__init__param.html">dc_init_param</a> for details about additional configuration options.</p>
<p>This spawning system is less flexibile due to the fixed port numbering. For instance, a crashed process will keep the port in TIMED_WAIT for a few minutes, preventing the next RPC process from running. This also prevents multiple different GraphLab RPC programs from running on the same set of the machines.</p>
<p>The MPI spawner is therefore the recommended method for starting the RPC system.</p>
<h1><a class="anchor" id="sec_rpc_usage"></a>
RPC Usage Overview</h1>
<p>The <a class="el" href="classgraphlab_1_1distributed__control.html" title="The distributed control object is primary means of communication between the distributed GraphLab pro...">graphlab::distributed_control</a> object provides asynchronous, multi-threaded Remote Procedure Call (RPC) services to allow distributed GraphLab processes to communicate with each other. Currently, the only communication method implemented is TCP/IP.</p>
<p>Each process is assigned a sequential process ID at starting at 0. i.e. The first process will have a process ID of 0, the second process will have an ID of 1, etc. <a class="el" href="classgraphlab_1_1distributed__control.html#a3adaa364edf63ff764aa2aabbe777f65" title="returns the id of the current process ">graphlab::distributed_control::procid()</a> can be used to obtain the current machine's process ID, and <a class="el" href="classgraphlab_1_1distributed__control.html#a688dac1ed2de771d65f93d7aae739fd1" title="returns the number of processes in total. ">graphlab::distributed_control::numprocs()</a> can be used to obtain the total number of processes.</p>
<p>The primary functions used to communicate between processes are <a class="el" href="classgraphlab_1_1distributed__control.html#aa0387b77bb3b5505d55fbebedd499b77" title="Performs a non-blocking RPC call to the target machine to run the provided function pointer...">graphlab::distributed_control::remote_call()</a> and <a class="el" href="classgraphlab_1_1distributed__control.html#a15abdebdf3d6ef44994661e562990380" title="Performs a blocking RPC call to the target machine to run the provided function pointer. ">graphlab::distributed_control::remote_request()</a>. These functions are thread-safe and can be called very rapidly as they only write into a local buffer. Communication is handled by a background thread. On the remote side, RPC calls are handled in parallel by a thread pool, and thus may be parallelized arbitrarily. Operations such as <a class="el" href="classgraphlab_1_1distributed__control.html#a7148dfdffd2e4b0fee75e528939bb982" title="A distributed barrier which waits for all machines to call the full_barrier() function before proceed...">graphlab::distributed_control::full_barrier()</a>, or the sequentialization key can be used to get finer grained control over order of execution on the remote machine.</p>
<p>A few other additional helper functions are also provided to support "synchronous" modes of communication. These functions are not thread-safe and can only be called on one thread per machine. These functions block until all machines call the same function. For instance, if gather() is called on one machine, it will not return until all machines call gather().</p>
<ul>
<li><a class="el" href="classgraphlab_1_1distributed__control.html#a32f0ebebb86a593fa56bf2c567f8c466" title="A distributed barrier which waits for all machines to call the barrier() function before proceeding...">graphlab::distributed_control::barrier()</a> </li>
<li><a class="el" href="classgraphlab_1_1distributed__control.html#a7148dfdffd2e4b0fee75e528939bb982" title="A distributed barrier which waits for all machines to call the full_barrier() function before proceed...">graphlab::distributed_control::full_barrier()</a> </li>
<li><a class="el" href="classgraphlab_1_1distributed__control.html#a9414f3bf9679b88b9e0074bdfc171653" title="This function allows one machine to broadcasts an object to all machines. ">graphlab::distributed_control::broadcast()</a> </li>
<li><a class="el" href="classgraphlab_1_1distributed__control.html#a86f19ef318f7f78ebf4496fbb6cb2180" title="Combines a value contributed by each machine, making the result available to all machines. ">graphlab::distributed_control::all_reduce()</a> </li>
<li><a class="el" href="classgraphlab_1_1distributed__control.html#a353f74d3aece1a8eafb1a436f3501fc7" title="Combines a value contributed by each machine, making the result available to all machines. ">graphlab::distributed_control::all_reduce2()</a> </li>
<li><a class="el" href="classgraphlab_1_1distributed__control.html#a235a274b33bb64ec76eeefba70ea54d0" title="Collects information contributed by each machine onto one machine. ">graphlab::distributed_control::gather()</a> </li>
<li><a class="el" href="classgraphlab_1_1distributed__control.html#a53bf32af89963f79f197b40a4abc24ff" title="Sends some information contributed by each machine to all machines. ">graphlab::distributed_control::all_gather()</a></li>
</ul>
<h2><a class="anchor" id="sec_basic_rpc_usage"></a>
Basic RPC</h2>
<p>Once the distributed_control is set up, it can be used to call functions on remote machines. For instance in the earlier example: </p><div class="fragment"><div class="line"><span class="keywordflow">if</span> (dc.<a class="code" href="classgraphlab_1_1distributed__control.html#a3adaa364edf63ff764aa2aabbe777f65">procid</a>() == 0) {</div>
<div class="line">  dc.<a class="code" href="classgraphlab_1_1distributed__control.html#aa0387b77bb3b5505d55fbebedd499b77">remote_call</a>(1, printf, <span class="stringliteral">&quot;%d + %f = %s\n&quot;</span>, 1, 2.0, <span class="stringliteral">&quot;three&quot;</span>);</div>
<div class="line">}</div>
</div><!-- fragment --><p> calls printf from machine 0 to machine 1 asynchronously.</p>
<p>In the GraphLab RPC terminology, a <b>call</b> is a one-way remote function call, while a <b>request</b> is a function call which has a return value. <b>calls</b> are executed asynchronously and returns immediately, while <b>requests</b> will wait for completion of the function on the remote machine.</p>
<p>For instance in the code below, machine 1 could print either "hello world", or "world hello". </p><div class="fragment"><div class="line"><span class="keywordflow">if</span> (dc.<a class="code" href="classgraphlab_1_1distributed__control.html#a3adaa364edf63ff764aa2aabbe777f65">procid</a>() == 0) {</div>
<div class="line">  dc.<a class="code" href="classgraphlab_1_1distributed__control.html#aa0387b77bb3b5505d55fbebedd499b77">remote_call</a>(1, printf, <span class="stringliteral">&quot;hello &quot;</span>);</div>
<div class="line">  dc.<a class="code" href="classgraphlab_1_1distributed__control.html#aa0387b77bb3b5505d55fbebedd499b77">remote_call</a>(1, printf, <span class="stringliteral">&quot;world &quot;</span>);</div>
<div class="line">}</div>
</div><!-- fragment --><p>Remote calls complete <b>immediately</b>, regardless of how long the function took on the other side. For instance, processor 0 will take almost no time running through this code. </p><div class="fragment"><div class="line"><span class="keywordflow">if</span> (dc.<a class="code" href="classgraphlab_1_1distributed__control.html#a3adaa364edf63ff764aa2aabbe777f65">procid</a>() == 0) {</div>
<div class="line">  dc.<a class="code" href="classgraphlab_1_1distributed__control.html#aa0387b77bb3b5505d55fbebedd499b77">remote_call</a>(1, sleep, 1);</div>
<div class="line">}</div>
</div><!-- fragment --><p>However, since requests will wait for completion and send back the reply, this could take about a second to run. </p><div class="fragment"><div class="line"><span class="keywordflow">if</span> (dc.<a class="code" href="classgraphlab_1_1distributed__control.html#a3adaa364edf63ff764aa2aabbe777f65">procid</a>() == 0) {</div>
<div class="line">  dc.<a class="code" href="classgraphlab_1_1distributed__control.html#a15abdebdf3d6ef44994661e562990380">remote_request</a>(1, sleep, 1);</div>
<div class="line">}</div>
</div><!-- fragment --><p>All arguments and return values will be passed by value. Any argument type or return type can be used as long as it is serializable.</p>
<h2><a class="anchor" id="sec_rpc_collective"></a>
Collective Operations</h2>
<p>In addition to regular RPC operations, A collection of MPI-like collective operations are also provided. A collective operation is a function which requires all machines to call the same function before execution can proceed.</p>
<h3><a class="anchor" id="sec_rpc_collective_barrier"></a>
Barrier</h3>
<p>One of the most useful operations is <a class="el" href="classgraphlab_1_1distributed__control.html#a32f0ebebb86a593fa56bf2c567f8c466" title="A distributed barrier which waits for all machines to call the barrier() function before proceeding...">graphlab::distributed_control::barrier()</a> The <a class="el" href="classbarrier.html">barrier()</a> is functionally equivalent to MPI_Barrier(). It requires all machines to hit the barrier, before execution is allowed to resume. For instance in the code below, while processor 0 is busy working at compute Pi, all other machines will pause at the barrier and wait for the processor 0 to complete computation and hit the barrier, before execution can proceed. </p><div class="fragment"><div class="line"><span class="keywordflow">if</span> (dc.<a class="code" href="classgraphlab_1_1distributed__control.html#a3adaa364edf63ff764aa2aabbe777f65">procid</a>() == 0) {</div>
<div class="line">  compute Pi to 1 million digits</div>
<div class="line">}</div>
<div class="line">dc.<a class="code" href="classgraphlab_1_1distributed__control.html#a32f0ebebb86a593fa56bf2c567f8c466">barrier</a>();</div>
</div><!-- fragment --><h3><a class="anchor" id="sec_rpc_collective_fullbarrier"></a>
Full Barrier</h3>
<p>A <a class="el" href="classgraphlab_1_1distributed__control.html#a7148dfdffd2e4b0fee75e528939bb982">Full Barrier</a> is also provided through <a class="el" href="classgraphlab_1_1distributed__control.html#a7148dfdffd2e4b0fee75e528939bb982" title="A distributed barrier which waits for all machines to call the full_barrier() function before proceed...">graphlab::distributed_control::full_barrier()</a>. A Full Barrier is like a barrier but guarantees that all RPC operations sent before the barrier must complete execution.</p>
<p>For instance in the example below, The full barrier guarantees that the call to set_a_to_1() must complete on all remote machines before execution is allowed to proceed. All machines will therefore print '1'. </p><div class="fragment"><div class="line"><span class="keywordtype">int</span> a = 0;</div>
<div class="line"><span class="keywordtype">void</span> set_a_to_1() { a = 1; }</div>
<div class="line"></div>
<div class="line"><span class="keywordtype">int</span> main(<span class="keywordtype">int</span> argc, <span class="keywordtype">char</span>** argv) {</div>
<div class="line">  graphlab::mpi_tools::init(argc, argv);</div>
<div class="line">  <a class="code" href="classgraphlab_1_1distributed__control.html">graphlab::distributed_control</a> dc;</div>
<div class="line"></div>
<div class="line">  dc.<a class="code" href="classgraphlab_1_1distributed__control.html#aa0387b77bb3b5505d55fbebedd499b77">remote_call</a>( [ another machine ], set_a_to_1);</div>
<div class="line">  dc.<a class="code" href="classgraphlab_1_1distributed__control.html#a7148dfdffd2e4b0fee75e528939bb982">full_barrier</a>();</div>
<div class="line">  std::cout &lt;&lt; a;</div>
<div class="line">}</div>
</div><!-- fragment --><p>The full_barrier is about 2-3x more costly than the regular barrier and should be used sparingly.</p>
<h3><a class="anchor" id="sec_rpc_collective_other_collectives"></a>
Other Collectives</h3>
<p>In addition to the barrier and the full barrier, operations such as broadcast, gather, all_gather are also provided. Note that the implementation of these operations are not particularly efficient as compared to native MPI implementations due to simplistic algorithm choices.</p>
<h2><a class="anchor" id="sec_rpc_sequentialization"></a>
Sequentialization</h2>
<p>A slightly more unusual feature of the GraphLab RPC system is the ability to enforce sequentialization of a sequence of RPC calls. This is particularly useful for asynchronous usages of this RPC library and can simplify code in many cases.</p>
<p>For instance, in the code below: </p><div class="fragment"><div class="line"><span class="keywordtype">int</span> a = 0;</div>
<div class="line"><span class="keywordtype">void</span> set_a_to_1() { a = 1; }</div>
<div class="line"><span class="keywordtype">void</span> print_a() { std::cout &lt;&lt; a; }</div>
<div class="line"></div>
<div class="line"><span class="keywordtype">int</span> main(<span class="keywordtype">int</span> argc, <span class="keywordtype">char</span>** argv) {</div>
<div class="line">  graphlab::mpi_tools::init(argc, argv);</div>
<div class="line">  <a class="code" href="classgraphlab_1_1distributed__control.html">graphlab::distributed_control</a> dc;</div>
<div class="line">  targetmachine = (dc.<a class="code" href="classgraphlab_1_1distributed__control.html#a3adaa364edf63ff764aa2aabbe777f65">procid</a>() + 1) % dc.<a class="code" href="classgraphlab_1_1distributed__control.html#a688dac1ed2de771d65f93d7aae739fd1">numprocs</a>();</div>
<div class="line">  dc.<a class="code" href="classgraphlab_1_1distributed__control.html#aa0387b77bb3b5505d55fbebedd499b77">remote_call</a>(targetmachine, set_a_to_1);</div>
<div class="line">  dc.<a class="code" href="classgraphlab_1_1distributed__control.html#aa0387b77bb3b5505d55fbebedd499b77">remote_call</a>(targetmachine, print_a);</div>
<div class="line">}</div>
</div><!-- fragment --><p> Note that due to the asynchronous nature of the remote_call, it is possible for <code>print_a()</code> to complete on the target machine, before the variable <code>a</code> is set to 1. Therefore, it is possible for the output to be '0'.</p>
<p>A possible solution as suggested before is to change the remote_calls to remote_requests. However, requests incur a large performance penalty due to the need to wait for replies.</p>
<p>Alternatively, we can use the sequentialization key system: </p><div class="fragment"><div class="line"><span class="comment">// set the sequentialization key to a non-zero value</span></div>
<div class="line"><span class="keywordtype">char</span> oldkey = <a class="code" href="classgraphlab_1_1distributed__control.html#a9946232b4ad672db290614d0b924881d">graphlab::distributed_control::set_sequentialization_key</a>(123);</div>
<div class="line"></div>
<div class="line">dc.<a class="code" href="classgraphlab_1_1distributed__control.html#aa0387b77bb3b5505d55fbebedd499b77">remote_call</a>(targetmachine, set_a_to_1);</div>
<div class="line">dc.<a class="code" href="classgraphlab_1_1distributed__control.html#aa0387b77bb3b5505d55fbebedd499b77">remote_call</a>(targetmachine, print_a);</div>
<div class="line"></div>
<div class="line"><a class="code" href="classgraphlab_1_1distributed__control.html#a9946232b4ad672db290614d0b924881d">graphlab::distributed_control::set_sequentialization_key</a>(oldkey);</div>
</div><!-- fragment --><p>Essentially all RPC calls made using the same key value (as long as the key value is non-zero) will sequentialize. This enforces that calls/requests made while a key is set will always be processed by the same thread in the thread pool on the target machine, ensuring sequentialization of the <code>set_a_to_1</code> and the <code>print_a</code> call.</p>
<p>The sequentialization key is unique to each <b>thread</b> (thread-local) so sequentialization of RPC calls in one thread will not affect RPC calls made by other threads.</p>
<h1><a class="anchor" id="OOP_RPC"></a>
Distributed Objects</h1>
<p>GraphLab provides a "distributed object" system which simplifies the process of designing data structures which provide distributed computation and storage.</p>
<p>A GraphLab distributed object is an object which is instantiated at the same time across all machines. The object internally contains a <code>dc_dist_object</code> which provides RPC communication between distributed instances.</p>
<p>For instance, say we run the following code using two machines: </p><div class="fragment"><div class="line"><span class="keywordtype">int</span> main(<span class="keywordtype">int</span> argc, <span class="keywordtype">char</span>** argv) {</div>
<div class="line">  graphlab::mpi_tools::init(argc, argv);</div>
<div class="line">  <a class="code" href="classgraphlab_1_1distributed__control.html">graphlab::distributed_control</a> dc;</div>
<div class="line"></div>
<div class="line">  <a class="code" href="classgraphlab_1_1dht.html">graphlab::dht&lt;std::string, std::string&gt;</a> str_map(dc);</div>
<div class="line">  dc.<a class="code" href="classgraphlab_1_1distributed__control.html#a32f0ebebb86a593fa56bf2c567f8c466">barrier</a>();</div>
<div class="line"></div>
<div class="line">  <span class="keywordflow">if</span> (dc.<a class="code" href="classgraphlab_1_1distributed__control.html#a3adaa364edf63ff764aa2aabbe777f65">procid</a>() == 0) {</div>
<div class="line">    str_map.set(<span class="stringliteral">&quot;hello&quot;</span>, <span class="stringliteral">&quot;world&quot;</span>);</div>
<div class="line">  }</div>
<div class="line">  <span class="keywordflow">else</span> <span class="keywordflow">if</span> (dc.<a class="code" href="classgraphlab_1_1distributed__control.html#a3adaa364edf63ff764aa2aabbe777f65">procid</a>() == 1) {</div>
<div class="line">    str_map.set(<span class="stringliteral">&quot;something&quot;</span>, <span class="stringliteral">&quot;other&quot;</span>);</div>
<div class="line">  }</div>
<div class="line">  dc.<a class="code" href="classgraphlab_1_1distributed__control.html#a32f0ebebb86a593fa56bf2c567f8c466">barrier</a>();</div>
<div class="line">  std::cout &lt;&lt; str_map.get(<span class="stringliteral">&quot;hello&quot;</span>).second;</div>
<div class="line">  std::cout &lt;&lt; str_map.get(<span class="stringliteral">&quot;something&quot;</span>).second;</div>
<div class="line">}</div>
</div><!-- fragment --><p> The DHT is a distributed object which provides a distributed key/value store (a distributed "Hash Table"). Every entry is stored at a machine corresponding to a hash of the key value. Note that it is created at the same time on all the machines. The <a class="el" href="classbarrier.html">barrier()</a> after creation ensures that the object is instantiated properly on all machines before utilization.</p>
<p>Now, after initialization, the <code>set</code> function of the dht will internally hash the key value and forward it to the right machine for processing. <code>get</code> is similar. However, since the distributed object system operates on <b>instances</b>, it is possible to create multiple distributed objects easily. For instance, the following code will create 50 different distributed key/value maps. str_map[15] corresponds to the same DHT when accessed on any machine. </p><div class="fragment"><div class="line"><a class="code" href="classgraphlab_1_1dht.html">graphlab::dht&lt;std::string, std::string&gt;</a>* str_map[50];</div>
<div class="line"><span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0;i &lt; 50; ++i) {</div>
<div class="line">  str_map[i] = <span class="keyword">new</span> <a class="code" href="classgraphlab_1_1dht.html">graphlab::dht&lt;std::string, std::string&gt;</a>(dc); </div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="sec_oop_rpc_usage"></a>
Usage</h2>
<p>We will demonstrate usage of the distributed object system using a simple distributed Hash Table example. Note that this is a <b>very</b> <b>simple</b> implementation, and is not entirely correct since we are going to ignore thread-safety. But it is sufficient to demonstrate the key concepts.</p>
<div class="fragment"><div class="line"><span class="keyword">class </span>string_dht { </div>
<div class="line"> <span class="keyword">private</span>:</div>
<div class="line">  std::map&lt;int, std::string&gt; local_storage;</div>
<div class="line">  <span class="keyword">mutable</span> dc_dist_object&lt;string_dht&gt; rmi;</div>
</div><!-- fragment --><p>First, each machine needs a local data storage. In this case we will simply use a std::map. The key object that provides distributed access is the <code>dc_dist_object&lt;string_dht&gt; rmi;</code>. This object creates a "context" for remote function calls, allowing the correct remote instance to be identified.</p>
<p>We will now look at the string_dht constructor. The rmi object constructor requires a reference to the underlying distributed_control object, as well as a pointer to the current instance: </p><div class="fragment"><div class="line"><span class="keyword">public</span>:</div>
<div class="line"> string_dht(distributed_control &amp;dc): rmi(dc, this) {  }</div>
</div><!-- fragment --><p>Now, to demonstrate how the RMI object is used, lets see the set() function </p><div class="fragment"><div class="line"><span class="keywordtype">void</span> set(<span class="keywordtype">int</span> key, <span class="keyword">const</span> std::string &amp;newval) {  </div>
<div class="line">  <a class="code" href="group__rpc.html#ga648487a0f9acffb0df08cf24804b1dcd">procid_t</a> owningmachine = key % rmi.numprocs();</div>
<div class="line">  <span class="keywordflow">if</span> (owningmachine == rmi.procid()) {</div>
<div class="line">    local_storage[key] = newval;</div>
<div class="line">  }</div>
</div><!-- fragment --><p> We use a simple hash function to identify where the key-value pair should be stored. Observe that the RMI object provides pretty much the same functionality as the <a class="el" href="classgraphlab_1_1distributed__control.html" title="The distributed control object is primary means of communication between the distributed GraphLab pro...">graphlab::distributed_control</a> object, having both <a class="el" href="classgraphlab_1_1dc__dist__object.html#a49f265ff4a28c800c43eb293bce0acad" title="The number of processes in the distributed program. ">graphlab::dc_dist_object::numprocs()</a> and <a class="el" href="classgraphlab_1_1dc__dist__object.html#ab35c107876915b9eef1266610b76f398" title="The current process ID. ">graphlab::dc_dist_object::procid()</a>. If the data is to be stored in the current machine, we simply store it. Otherwise we will need to send it to a remote machine for storage. This is the interesting case:</p>
<div class="fragment"><div class="line">  <span class="keywordflow">else</span> {</div>
<div class="line">    rmi.remote_call(owningmachine,</div>
<div class="line">                    &amp;string_dht::set,</div>
<div class="line">                    key,</div>
<div class="line">                    newval);</div>
<div class="line">  }</div>
<div class="line">}</div>
</div><!-- fragment --><p>The RMI object supports the same family of call/request operations as distributed_control However, it will only work with <b>member function pointers</b>. For instance in this case, we will be calling the set() member function on the matching instance of the string_dht object on a remote machine. (Note that the &amp; is important and necessary)</p>
<p>The get() function is similar. However, we will have to use remote requests.</p>
<div class="fragment"><div class="line">std::string <span class="keyword">get</span>(<span class="keywordtype">int</span> key) {  </div>
<div class="line">  <a class="code" href="group__rpc.html#ga648487a0f9acffb0df08cf24804b1dcd">procid_t</a> owningmachine = key % rmi.numprocs();</div>
<div class="line">  <span class="keywordflow">if</span> (owningmachine == rmi.procid()) {</div>
<div class="line">    <span class="keywordflow">return</span> local_storage[key];</div>
<div class="line">  }</div>
<div class="line">  <span class="keywordflow">else</span> {</div>
<div class="line">    <span class="keywordflow">return</span> rmi.remote_request(owningmachine,</div>
<div class="line">                              &amp;string_dht::get,</div>
<div class="line">                              key);</div>
<div class="line">  }</div>
<div class="line">}</div>
</div><!-- fragment --><p>As stated earlier, this code should not be used as it is due to several limitations such as the local_storage object is not thread-safe. Since incoming RPC calls are generally multithreaded, locks are necessary. See <a class="el" href="dht_8hpp_source.html">dht.hpp</a> for an equivalent "safe" example of a simple DHT.</p>
<h2><a class="anchor" id="sec_oop_rpc_context"></a>
Context</h2>
<p>Essentially, the dc_dist_object object supports the identical set of operations as the distributed_control object, but restricted to the <b>context</b> of a single object instance.</p>
<p>It includes all the regular call operations: </p><ul>
<li><a class="el" href="classgraphlab_1_1dc__dist__object.html#a0c423bdc58f79caf04da261b97454d01" title="Performs a non-blocking RPC call to the target machine to run the provided function pointer...">graphlab::dc_dist_object::remote_call()</a> </li>
<li><a class="el" href="classgraphlab_1_1dc__dist__object.html#a23845fd5c66033a13a5c689a65583f1b" title="Performs a blocking RPC call to the target machine to run the provided function pointer. ">graphlab::dc_dist_object::remote_request()</a></li>
</ul>
<p>Additionally, this <b>context</b> is entirely independent of the distributed_control object, permitting its own set of collective operations such as <a class="el" href="classgraphlab_1_1dc__dist__object.html#a0a79863a2e99e5873d914db2068254d7" title="This function allows one machine to broadcasts an object to all machines. ">graphlab::dc_dist_object::broadcast</a>, <a class="el" href="classgraphlab_1_1dc__dist__object.html#aec8dee7f045c5186a0015aba5ca44e8f" title="A distributed barrier which waits for all machines to call the barrier() function before proceeding...">graphlab::dc_dist_object::barrier</a>, <a class="el" href="classgraphlab_1_1dc__dist__object.html#a5478c426fd12ef635f67ec6b7faf2f21" title="A distributed barrier which waits for all machines to call the full_barrier() function before proceed...">graphlab::dc_dist_object::full_barrier</a>, etc</p>
<p>Since these collective operations also operate entirely within the context of the object instance, this permits the use of parallel collectives. For instance, I could have two objects, and each object internally spawns threads to perform distributed computation; using the RMI object to perform collective operations which are local to the object.</p>
<p>In particular, the <a class="el" href="classgraphlab_1_1dc__dist__object.html#a5478c426fd12ef635f67ec6b7faf2f21" title="A distributed barrier which waits for all machines to call the full_barrier() function before proceed...">graphlab::dc_dist_object::full_barrier()</a> is worth taking note of. The <a class="el" href="classgraphlab_1_1distributed__control.html#a7148dfdffd2e4b0fee75e528939bb982" title="A distributed barrier which waits for all machines to call the full_barrier() function before proceed...">graphlab::distributed_control::full_barrier()</a> ensures completion of ALL RPC calls including calls meant for distributed objects. Its barrier is therefore <b>global</b> to the state of the program as a while. The <a class="el" href="classgraphlab_1_1dc__dist__object.html#a5478c426fd12ef635f67ec6b7faf2f21" title="A distributed barrier which waits for all machines to call the full_barrier() function before proceed...">graphlab::dc_dist_object::full_barrier()</a> however, only ensures completion of all RPC calls within the object instance. Its barrier is therefore <b>local</b> to the state of the distributed object. This allows each distributed object to run its own full barriers without affecting other distributed objects.</p>
<h2><a class="anchor" id="sec_oop_rpc_notes"></a>
Final Notes</h2>
<p>Finally, note that the RMI object can ONLY call member function pointers. It cannot call other global functions (such as printf). The global context can be accessed through <a class="el" href="classgraphlab_1_1dc__dist__object.html#a2f98d089ad572f59c05186925f3a01fb" title="A reference to the underlying distributed_control object. ">graphlab::dc_dist_object::dc()</a> which returns the underlying distributed_control object, which can then be used to call global functions. For instance: </p><div class="fragment"><div class="line">rmi.dc().remote_call(1, printf, <span class="stringliteral">&quot;hello &quot;</span>);</div>
</div><!-- fragment --><h1><a class="anchor" id="Fiber_RPC"></a>
Fiber Compatible Remote Requests</h1>
<p>To support the fiber architecture required for the Warp Engine, we provide the following functions:</p>
<ul>
<li><a class="el" href="namespacegraphlab.html#ae9e66287c580fe28c89478750b83f230" title="Performs a nonblocking RPC call to the target machine to run the provided function pointer which has ...">graphlab::fiber_remote_request()</a> </li>
<li><a class="el" href="namespacegraphlab.html#ab6d8bc6faaeeb404cde12aa9b650ffd2" title="Performs a nonblocking RPC call to the target machine to run the provided function pointer which has ...">graphlab::object_fiber_remote_request()</a></li>
</ul>
<p>These two functions are special in that unlike the remote_request functions, they return immediately with a future object.</p>
<p>For instance:</p>
<div class="fragment"><div class="line"><span class="keywordtype">int</span> add_one(<span class="keywordtype">int</span> a) {</div>
<div class="line">  <span class="keywordflow">return</span> a + 1;</div>
<div class="line">}</div>
<div class="line"></div>
<div class="line">... <span class="comment">/* elsewhere */</span></div>
<div class="line"><a class="code" href="structgraphlab_1_1request__future.html">graphlab::request_future&lt;int&gt;</a> future = <a class="code" href="namespacegraphlab.html#ae9e66287c580fe28c89478750b83f230">fiber_remote_request</a>(1, <span class="comment">/* call to machine 1 */</span></div>
<div class="line">                                                            add_one,</div>
<div class="line">                                                            1);</div>
</div><!-- fragment --><p>Waiting on the future, using either: </p><div class="fragment"><div class="line"><span class="keywordtype">int</span> ret = future();</div>
<div class="line"><span class="comment">/* Or, more explicitly ... */</span></div>
<div class="line">future.<a class="code" href="structgraphlab_1_1request__future.html#a950a29dbe1ef7e24abbfed5e31e2af67">wait</a>();</div>
<div class="line"><span class="keywordtype">int</span> ret = future();</div>
</div><!-- fragment --><p>Will block until the result is available. This wait, however, is optimized if the caller is in a fiber, in which case the fiber is descheduled, allowing other fibers to execute while waiting for the result.</p>
<p>The <a class="el" href="namespacegraphlab.html#ab6d8bc6faaeeb404cde12aa9b650ffd2" title="Performs a nonblocking RPC call to the target machine to run the provided function pointer which has ...">graphlab::object_fiber_remote_request()</a> function is similar, but allows for calling of member functions of a class. </p>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Mon Dec 29 2014 17:16:26 for GraphLab: Distributed Graph-Parallel API by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.9 </li>
  </ul>
</div>
</body>
</html>
